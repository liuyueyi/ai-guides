const e=JSON.parse('{"key":"v-094a1db7","path":"/tutorial/hello-llm/13.%E8%AE%B0%E5%BF%86%E7%AD%96%E7%95%A5.html","title":"第 8 章：记忆策略的工程化选择","lang":"zh-CN","frontmatter":{"order":13,"title":"第 8 章：记忆策略的工程化选择","tag":["LLM"],"category":["LLM"],"date":"2025-12-30T14:55:07.000Z","keywords":"LLM应用开发","description":"在前两章中，我们已经完成了两个关键决策： 否定“无限上下文”的幻想：明确上下文窗口存在硬性约束，无法承载无限制的对话信息； 接受“信息必须被分层管理”：将信息划分为不变约束、会话状态、瞬时上下文，优先保障高优先级信息的有效性。 接下来，我们需要面对一个更系统级的问题，当然这也是很多小伙伴在具体落地时，最容易困惑的地方 “记忆”是否应该只有一种实现方式？ 答案显然是否定的，就像人类会用“瞬时回忆”记住刚说的话、用“短期记忆”记住当天的任务、用“长期记忆”记住过往的经验一样，大模型应用的“记忆”也需要分层设计","head":[["meta",{"property":"og:url","content":"https://ppai.top/ai-guides/tutorial/hello-llm/13.%E8%AE%B0%E5%BF%86%E7%AD%96%E7%95%A5.html"}],["meta",{"property":"og:site_name","content":"Helllo LLM Guides"}],["meta",{"property":"og:title","content":"第 8 章：记忆策略的工程化选择"}],["meta",{"property":"og:description","content":"在前两章中，我们已经完成了两个关键决策： 否定“无限上下文”的幻想：明确上下文窗口存在硬性约束，无法承载无限制的对话信息； 接受“信息必须被分层管理”：将信息划分为不变约束、会话状态、瞬时上下文，优先保障高优先级信息的有效性。 接下来，我们需要面对一个更系统级的问题，当然这也是很多小伙伴在具体落地时，最容易困惑的地方 “记忆”是否应该只有一种实现方式？ 答案显然是否定的，就像人类会用“瞬时回忆”记住刚说的话、用“短期记忆”记住当天的任务、用“长期记忆”记住过往的经验一样，大模型应用的“记忆”也需要分层设计"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-02-04T07:10:37.000Z"}],["meta",{"property":"article:tag","content":"LLM"}],["meta",{"property":"article:published_time","content":"2025-12-30T14:55:07.000Z"}],["meta",{"property":"article:modified_time","content":"2026-02-04T07:10:37.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"第 8 章：记忆策略的工程化选择\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-12-30T14:55:07.000Z\\",\\"dateModified\\":\\"2026-02-04T07:10:37.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":3,"title":"8.1 技术决策视角：记忆不是功能，而是策略组合","slug":"_8-1-技术决策视角-记忆不是功能-而是策略组合","link":"#_8-1-技术决策视角-记忆不是功能-而是策略组合","children":[]},{"level":3,"title":"8.2 短期记忆：受控的上下文拼接（什么时候足够用）","slug":"_8-2-短期记忆-受控的上下文拼接-什么时候足够用","link":"#_8-2-短期记忆-受控的上下文拼接-什么时候足够用","children":[]},{"level":3,"title":"8.3 中期记忆：由 LLM 维护的状态摘要（为什么要引入）","slug":"_8-3-中期记忆-由-llm-维护的状态摘要-为什么要引入","link":"#_8-3-中期记忆-由-llm-维护的状态摘要-为什么要引入","children":[]},{"level":3,"title":"8.4 长期记忆：为什么不能继续塞进上下文？","slug":"_8-4-长期记忆-为什么不能继续塞进上下文","link":"#_8-4-长期记忆-为什么不能继续塞进上下文","children":[]},{"level":3,"title":"8.5 短中长记忆协同工作流程","slug":"_8-5-短中长记忆协同工作流程","link":"#_8-5-短中长记忆协同工作流程","children":[]},{"level":3,"title":"8.6 本章小结：记忆层次决定系统上限","slug":"_8-6-本章小结-记忆层次决定系统上限","link":"#_8-6-本章小结-记忆层次决定系统上限","children":[]}],"git":{"createdTime":1770189037000,"updatedTime":1770189037000,"contributors":[{"name":"yihui","email":"bangzewu@126.com","commits":1}]},"readingTime":{"minutes":14.4,"words":4321},"filePathRelative":"tutorial/hello-llm/13.记忆策略.md","localizedDate":"2025年12月30日","excerpt":"<p>在前两章中，我们已经完成了两个关键决策：</p>\\n<ul>\\n<li>否定“无限上下文”的幻想：明确上下文窗口存在硬性约束，无法承载无限制的对话信息；</li>\\n<li>接受“信息必须被分层管理”：将信息划分为不变约束、会话状态、瞬时上下文，优先保障高优先级信息的有效性。</li>\\n</ul>\\n<p>接下来，我们需要面对一个更系统级的问题，当然这也是很多小伙伴在具体落地时，最容易困惑的地方</p>\\n<blockquote>\\n<p><strong>“记忆”是否应该只有一种实现方式？</strong></p>\\n</blockquote>\\n<p>答案显然是否定的，就像人类会用“瞬时回忆”记住刚说的话、用“短期记忆”记住当天的任务、用“长期记忆”记住过往的经验一样，大模型应用的“记忆”也需要分层设计</p>","copyright":{},"autoDesc":true}');export{e as data};
