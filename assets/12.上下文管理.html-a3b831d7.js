const t=JSON.parse('{"key":"v-799e4442","path":"/tutorial/hello-llm/12.%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86.html","title":"第 7 章：从 “堆上下文” 到 “管理上下文”","lang":"zh-CN","frontmatter":{"order":12,"title":"第 7 章：从 “堆上下文” 到 “管理上下文”","tag":["LLM"],"category":["LLM"],"date":"2025-12-30T14:25:07.000Z","keywords":"LLM应用开发","description":"在上一章中，我们已经明确否定了一种做法： 把上下文当作“无限可用的记忆容器”。 在大模型应用给开发时，上下文窗口的限制是一个不得不考虑的问题，不管是哪个模型，终究是有一个长度上限，显然有上限那么就不可能满足无限轮次的对话存储，因此一个更难、也更重要的问题也就出来了： 在有限的上下文窗口里，哪些信息值得被保留？ 首先我们的明确，这不是大模型需要关注的事情，而是我们这种基于大模型做应用开发的苦逼码农需要重点考虑的系统设计决策 —— 它的具体设计，直接决定了多轮对话中系统的稳定性、准确性，甚至是用户对我们产品的信任度","head":[["meta",{"property":"og:url","content":"https://liuyueyi.github.io/ai-guides/tutorial/hello-llm/12.%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86.html"}],["meta",{"property":"og:site_name","content":"Helllo LLM Guides"}],["meta",{"property":"og:title","content":"第 7 章：从 “堆上下文” 到 “管理上下文”"}],["meta",{"property":"og:description","content":"在上一章中，我们已经明确否定了一种做法： 把上下文当作“无限可用的记忆容器”。 在大模型应用给开发时，上下文窗口的限制是一个不得不考虑的问题，不管是哪个模型，终究是有一个长度上限，显然有上限那么就不可能满足无限轮次的对话存储，因此一个更难、也更重要的问题也就出来了： 在有限的上下文窗口里，哪些信息值得被保留？ 首先我们的明确，这不是大模型需要关注的事情，而是我们这种基于大模型做应用开发的苦逼码农需要重点考虑的系统设计决策 —— 它的具体设计，直接决定了多轮对话中系统的稳定性、准确性，甚至是用户对我们产品的信任度"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-27T09:13:38.000Z"}],["meta",{"property":"article:tag","content":"LLM"}],["meta",{"property":"article:published_time","content":"2025-12-30T14:25:07.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-27T09:13:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"第 7 章：从 “堆上下文” 到 “管理上下文”\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-12-30T14:25:07.000Z\\",\\"dateModified\\":\\"2026-01-27T09:13:38.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":3,"title":"7.1 技术决策的第一步：承认信息是有“等级”的","slug":"_7-1-技术决策的第一步-承认信息是有-等级-的","link":"#_7-1-技术决策的第一步-承认信息是有-等级-的","children":[]},{"level":3,"title":"7.2 为什么“直接摘要历史”并不是银弹？","slug":"_7-2-为什么-直接摘要历史-并不是银弹","link":"#_7-2-为什么-直接摘要历史-并不是银弹","children":[]},{"level":3,"title":"7.3 本章小结：上下文开始变成工程对象","slug":"_7-3-本章小结-上下文开始变成工程对象","link":"#_7-3-本章小结-上下文开始变成工程对象","children":[]}],"git":{"createdTime":1769505218000,"updatedTime":1769505218000,"contributors":[{"name":"yihui","email":"bangzewu@126.com","commits":1}]},"readingTime":{"minutes":10.31,"words":3093},"filePathRelative":"tutorial/hello-llm/12.上下文管理.md","localizedDate":"2025年12月30日","excerpt":"<p>在上一章中，我们已经明确否定了一种做法：</p>\\n<blockquote>\\n<p><strong>把上下文当作“无限可用的记忆容器”。</strong></p>\\n</blockquote>\\n<p>在大模型应用给开发时，上下文窗口的限制是一个不得不考虑的问题，不管是哪个模型，终究是有一个长度上限，显然有上限那么就不可能满足无限轮次的对话存储，因此一个更难、也更重要的问题也就出来了：</p>\\n<blockquote>\\n<p><strong>在有限的上下文窗口里，哪些信息值得被保留？</strong></p>\\n</blockquote>\\n<p>首先我们的明确，这不是大模型需要关注的事情，而是我们这种基于大模型做应用开发的苦逼码农需要重点考虑的<strong>系统设计决策</strong> —— 它的具体设计，直接决定了多轮对话中系统的稳定性、准确性，甚至是用户对我们产品的信任度</p>","copyright":{},"autoDesc":true}');export{t as data};
